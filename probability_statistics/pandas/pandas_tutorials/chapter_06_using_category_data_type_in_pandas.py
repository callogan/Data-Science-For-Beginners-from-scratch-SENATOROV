"""Using the category data type in pandas."""

# # Использование типа данных категории в pandas

# ## Введение
#
# В [предыдущей статье](https://pbpython.com/pandas_dtypes.html) (а [тут](http://dfedorov.spb.ru/pandas/%D0%9E%D0%B1%D0%B7%D0%BE%D1%80%20%D1%82%D0%B8%D0%BF%D0%BE%D0%B2%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85%20pandas.html) перевод на русский язык) я писал о типах данных в pandas; что это такое и как преобразовать данные в соответствующий тип. В этой статье основное внимание будет уделено [категориальному типу данных](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html), а также некоторым преимуществам и недостаткам его использования.
#
# > Оригинал статьи Криса [тут](https://pbpython.com/pandas_dtypes_cat.html).

# ## Тип данных Category в pandas
#
# В этой статье речь пойдет о категориальных данных. Напоминаю, что категориальные данные - это данные, которые принимают конечное число возможных значений. Например, если мы говорим о таком товаре как футболка, у него могут быть следующие категориальные значения:
#
# - `Размер` (X-Small, Small, Medium, Large, X-Large) 
# - `Цвет` (красный, черный, белый) 
# - `Стиль` (короткий рукав, длинный рукав) 
# - `Материал` (хлопок, полиэстер)
#
# Такие атрибуты, как стоимость, цена, количество, обычно являются целыми числами или числами с плавающей точкой. 
#
# Является ли переменная категориальной, зависит от ее применения. Поскольку у нас всего 3 цвета рубашек, то это хорошая категориальная переменная. Однако в другом случае "цвет" может представлять тысячи значений.
#
# *Не существует жесткого правила, определяющего, сколько значений должна иметь категориальная переменная*. Вы должны использовать собственные знания о предметной области, чтобы сделать выбор. В этой статье мы рассмотрим один из подходов к определению категориальных значений.
#
# Тип данных категории (`category data type`) в pandas - это гибридный тип. Во многих случаях он выглядит и ведет себя как строка, но внутренне представлен массивом целых чисел. Это позволяет сортировать данные в произвольном порядке и более эффективно их хранить.
#
# В конце концов, почему мы так беспокоимся об использовании категориальных значений? Есть 3 основные причины:
#
# - Мы можем определить собственный порядок сортировки, который позволяет улучшить обобщение данных и составление отчетов. В приведенном выше примере `X-Small < Small < Medium < Large < X-Large`. Алфавитная сортировка не сможет воспроизвести этот порядок.
# - Некоторые из питоновских библиотек визуализации позволяют интерпретировать категориальный тип данных для применения подходящих статистических моделей или типов графиков.
# - Категориальные данные используют меньше памяти, что приводит к повышению производительности.
#
# ## Подготовка данных
#
# Одно из основных преимуществ категориальных типов данных - более эффективное использование памяти. Для демонстрации этого будем использовать [большой набор данных из Центров услуг Медикэр и Медикэйд в США](https://www.cms.gov/OpenPayments/Explore-the-Data/Dataset-Downloads.html). Этот набор данных включает csv файл размером 500 МБ+, содержащий информацию о платежах за исследования врачам и больницам в 2017 финансовом году ([прямая ссылка](https://download.cms.gov/openpayments/PGYR17_P063020.ZIP) на скачивание архива).
#
# Сначала настройте импорт и прочтите все данные:

# +
import pandas as pd

# https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html#categoricaldtype
from pandas.api.types import CategoricalDtype
# -

# !wget https://www.dropbox.com/s/jou3p1zdyvjmq4e/OP_DTL_RSRCH_PGYR2017_P06302020.csv

df_raw = pd.read_csv("OP_DTL_RSRCH_PGYR2017_P06302020.csv", low_memory=False)
df_raw.head()

# Я установил параметр `low_memory=False`, как указано в предупреждении:
#
# ```
# interactiveshell.py:2728: DtypeWarning: Columns (..) have mixed types. Specify dtype option on import or set low_memory=False.
# interactivity=interactivity, compiler=compiler, result=result)
# ```

# > Не стесняйтесь прочитать об этом параметре в документации по [`read_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html).
#
# В этом наборе данных есть одна интересная особенность: в нем более 176 столбцов, но многие из них пусты. Я нашел [решение на stack overflow](https://stackoverflow.com/questions/49791246/drop-columns-with-more-than-60-percent-of-empty-values-in-pandas), позволяющее быстро удалить столбцы, в которых не менее 90% данных отсутствуют. 
#
# Думаю, что это решение может быть полезно и для других:

drop_thresh: int = int(df_raw.shape[0] * 0.9)
df = df_raw.dropna(thresh=drop_thresh, how="all", axis="columns").copy()

# Давайте посмотрим на размер различных кадров данных. Вот исходный набор данных:

df_raw.info()

# CSV-файл размером `560 МБ` занимает в памяти около `904 МБ`. Кажется, что это много, но даже в слабом ноутбуке есть несколько гигабайт оперативной памяти, поэтому нам не понадобятся специализированные инструменты обработки.

# Вот набор данных, который мы будем использовать в оставшейся части Блокнота:

df.info()

# Теперь, когда у нас есть 33 столбца, занимающих `174,6 МБ` памяти, давайте посмотрим, какие столбцы могут стать хорошими кандидатами для категориального типа данных.
#
# Чтобы упростить задачу, я создал небольшую вспомогательную функцию для формирования кадра данных, показывающего все уникальные значения в столбце.

# +
# from_records: создает объект DataFrame из структурированного массива

unique_counts = pd.DataFrame.from_records(
    [(col, df[col].nunique()) for col in df.columns],
    columns=["Column_Name", "Num_Unique"],
).sort_values(by=["Num_Unique"])
# -

unique_counts

# Эта таблица указывает на несколько моментов, которые помогают определить категориальные значения. Во-первых, когда мы превышаем `649` уникальных значений, то происходит резкий скачок. Это может стать полезным пределом для данного набора.
#
# Кроме того, поля с датами не следует преобразовывать в категориальные.
#
# Самый простой способ преобразовать столбец в категориальный тип - использовать `astype('category')`. 
#
# Мы можем использовать цикл для преобразования всех столбцов, которые нам нужны, используя `astype('category')`:

# +
cols_to_exclude = ["Program_Year", "Date_of_Payment", "Payment_Publication_Date"]

for col in df.columns:
    if df[col].nunique() < 700 and col not in cols_to_exclude:
        df[col] = df[col].astype("category")
# -

# Если мы вызовем `df.info()` для просмотра используемой памяти, то увидим уменьшение кадра данных с `175 МБ` до `92 МБ`: 

df.info()

# Это впечатляет! Мы сократили использование памяти почти вдвое, просто преобразовав большинство столбцов в категориальные значения.

# Есть еще одна функция, которую можно использовать с категориальными данными - определение пользовательского порядка.
#
# Чтобы проиллюстрировать это, давайте сделаем краткую сводку общей суммы платежей, произведенных с использованием одного из способов оплаты:

# +
# to_frame(): преобразует Series в DataFrame

df.groupby("Covered_Recipient_Type")[
    "Total_Amount_of_Payment_USDollars"
].sum().to_frame()
# -

# Если мы хотим изменить порядок `Covered_Recipient_Type`, то нам нужно определить настраиваемый [`CategoricalDtype`](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html#categoricaldtype):

# +
# расположение в списке задает будущий порядок сортировки категорий от меньшей к большей

cats_to_order = [
    "Non-covered Recipient Entity",
    "Covered Recipient Teaching Hospital",
    "Covered Recipient Physician",
    "Non-covered Recipient Individual",
]
# -

covered_type = CategoricalDtype(
    categories=cats_to_order, ordered=True
)  # учитывать порядок категорий
covered_type

# Затем явно измените порядок категории в столбце:

# +
# https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.reorder_categories.html

df["Covered_Recipient_Type"] = df["Covered_Recipient_Type"].cat.reorder_categories(
    cats_to_order, ordered=True
)
df["Covered_Recipient_Type"][:3]
# -

# Теперь можем увидеть порядок сортировки в `groupby`:

df.groupby("Covered_Recipient_Type")[
    "Total_Amount_of_Payment_USDollars"
].sum().to_frame()

# Можете указать это преобразование при чтении CSV файла, передав словарь имен и типов столбцов через параметр `dtype`:

df_raw_2 = pd.read_csv(
    "OP_DTL_RSRCH_PGYR2017_P06302020.csv",
    dtype={"Covered_Recipient_Type": covered_type},
    low_memory=False,
)

# ## Производительность
#
# Мы показали, что размер кадра данных уменьшается за счет преобразования значений в категориальные типы данных. Влияет ли это на другие сферы деятельности? Ответ положительный.
#
# Вот пример операции `groupby` над категориальными (`categorical`) типами данных против типа данных `object`. 
#
# Сначала выполните анализ исходного кадра данных:

# %%timeit
df_raw.groupby("Covered_Recipient_Type")[
    "Total_Amount_of_Payment_USDollars"
].sum().to_frame()

# Далее кадр данных с категориальными типами:

# %%timeit
df.groupby("Covered_Recipient_Type")[
    "Total_Amount_of_Payment_USDollars"
].sum().to_frame()

# Мы ускорили код в 10 раз с `55,3 мс` до `4,17 мс`. Вы можете себе представить, что на гораздо больших наборах данных ускорение может быть еще большим!

# ## Осторожно
#
# Категориальные данные кажутся довольно изящными. Это экономит память и ускоряет код, так почему бы не использовать их везде? Что ж, [Дональд Кнут](https://ru.wikipedia.org/wiki/%D0%9A%D0%BD%D1%83%D1%82,_%D0%94%D0%BE%D0%BD%D0%B0%D0%BB%D1%8C%D0%B4_%D0%AD%D1%80%D0%B2%D0%B8%D0%BD) прав, когда предупреждает о преждевременной оптимизации (рекомендую [сайт](http://optimization.guide/) на русском языке):
#
# > Программисты тратят огромное количество времени, размышляя и беспокоясь о некритичных местах кода, и пытаются оптимизировать их, что исключительно негативно сказывается на последующей отладке и поддержке. Мы должны вообще забыть об оптимизации в, скажем, 97% случаев. Поспешная оптимизация является корнем всех зол. И, напротив, мы должны уделить все внимание оставшимся 3%.
#
# В приведенных выше примерах код работает быстрее, но это не имеет значения, когда он используется для быстрых сводных действий, которые выполняются нечасто. Кроме того, вся работа по вычислению и преобразованию в категориальные данные, вероятно, не стоит затраченных усилий для этого набора данных и простого анализа.
#
# Также категориальные данные могут привести к неожиданным результатам при использовании в реальном мире. Приведенные ниже примеры проиллюстрируют несколько проблем.
#
# Давайте создадим простой кадр данных с одной упорядоченной категориальной переменной, которая представляет статус клиента. Этот тривиальный пример выделит некоторые потенциальные тонкие ошибки при работе с категориальными переменными. 
#
# Стоит отметить, что в примере показано, как использовать `astype()` для преобразования в упорядоченную категорию за один шаг вместо двухэтапного процесса, который использовался ранее.

sales_1 = [
    {"account": "Jones LLC", "Status": "Gold", "Jan": 150, "Feb": 200, "Mar": 140},
    {"account": "Alpha Co", "Status": "Gold", "Jan": 200, "Feb": 210, "Mar": 215},
    {"account": "Blue Inc", "Status": "Silver", "Jan": 50, "Feb": 90, "Mar": 95},
]

df_1 = pd.DataFrame(sales_1)
df_1

status_type = CategoricalDtype(categories=["Silver", "Gold"], ordered=True)

df_1["Status"] = df_1["Status"].astype(status_type)

# В результате получается простой кадр данных, который выглядит так:

df_1

# Можем рассмотреть категориальный столбец более подробно:

df_1["Status"]

# Все выглядит хорошо. 
#
# Мы видим, что все данные присутствуют и `Gold > Silver`. 
#
# Теперь давайте добавим еще один кадр данных и применим ту же категорию к столбцу статуса:

sales_2 = [
    {"account": "Smith Co", "Status": "Silver", "Jan": 100, "Feb": 100, "Mar": 70},
    {"account": "Bingo", "Status": "Bronze", "Jan": 310, "Feb": 65, "Mar": 80},
]

df_2 = pd.DataFrame(sales_2)
df_2.head()

df_2["Status"] = df_2["Status"].astype(status_type)
df_2["Status"]

df_2

# Хм. Что-то случилось с нашим статусом.
#
# Посмотрим на столбец:

df_2["Status"]

# Поскольку мы не определили `Bronze` как действующий статус, то получаем значение `NaN`. Pandas делает это по вполне уважительной причине. Предполагается, что вы заранее определили все допустимые категории. 
#
# Можно только представить, насколько запутанной могла бы стать эта проблема, если бы вы ее сразу не нашли.
#
# Этот сценарий относительно легко обнаружить, но что бы вы сделали, если бы было 100 значений, а данные не были очищены и нормализованы?
#
# Вот еще один хитрый пример, когда вы можете "потерять" категориальный тип данных:

sales_1 = [
    {"account": "Jones LLC", "Status": "Gold", "Jan": 150, "Feb": 200, "Mar": 140},
    {"account": "Alpha Co", "Status": "Gold", "Jan": 200, "Feb": 210, "Mar": 215},
    {"account": "Blue Inc", "Status": "Silver", "Jan": 50, "Feb": 90, "Mar": 95},
]

df_1 = pd.DataFrame(sales_1)
df_1

# Определим неупорядоченную категорию
df_1["Status"] = df_1["Status"].astype("category")
df_1["Status"]

sales_2 = [
    {"account": "Smith Co", "Status": "Silver", "Jan": 100, "Feb": 100, "Mar": 70},
    {"account": "Bingo", "Status": "Bronze", "Jan": 310, "Feb": 65, "Mar": 80},
]

df_2 = pd.DataFrame(sales_2)
df_2

df_2["Status"] = df_2["Status"].astype("category")
df_2["Status"]

# Объединим два кадра данных в 1
df_combined = pd.concat([df_1, df_2])

df_combined

# Все выглядит нормально, но при дополнительном осмотре мы потеряли категоририальный тип данных:

df_combined["Status"]

# В этом примере все данные на месте, но тип был преобразован в `object`. Опять же, это попытка pandas объединить данные без ошибок и без предположений. Если вы хотите преобразовать данные в тип категории, то можете использовать `astype('category')`.
#
# ## Общие рекомендации
#
# Теперь, когда вы знаете об этих подводных камнях, то можете их отслеживать. 
# Я дам несколько рекомендаций, как использовать категориальные типы данных:
#
# 1. Не думайте, что вам нужно преобразовать все категориальные данные в тип данных категории (`category`) pandas.
# 2. Если набор данных занимает значительный процент используемой памяти, рассмотрите возможность использования категориальных типов данных.
# 3. Если у вас очень серьезные проблемы с производительностью с часто выполняемыми операциями, обратите внимание на использование категориальных данных.
# 4. Если вы используете категориальные данные, добавьте несколько проверок, чтобы убедиться, что данные чистые и полные, перед преобразованием в тип категории pandas. Кроме того, проверьте значения `NaN` после объединения или преобразования кадров данных.
#
# Надеюсь, эта статья была полезной. Категориальные типы данных в pandas могут быть очень полезны. Однако есть несколько проблем, на которые нужно обратить внимание, чтобы не запутаться в последующей обработке. 
