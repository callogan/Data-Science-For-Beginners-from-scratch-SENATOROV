{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66c87a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Working with files in Google Colab.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b747804",
   "metadata": {},
   "source": [
    "## Работа с файлами в Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48966b80",
   "metadata": {},
   "source": [
    "### Этап 1. Подгрузка файлов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899ff54",
   "metadata": {},
   "source": [
    "Способ 1. Вручную через вкладку 'Файлы'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d97788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# см. материалы урока на сайте"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903187f4",
   "metadata": {},
   "source": [
    "Способ 2. Через модуль files библиотеки google.colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ab009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выполняем все необходимы импорты\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from google.colab import files\n",
    "\n",
    "# импортируем логистическую регрессию из модуля linear_model библиотеки sklearn\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93d609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем объект этого класса, применяем метод .upload()\n",
    "uploaded: dict[str, bytes] = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe321f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на содержимое словаря uploaded\n",
    "# uploaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e34cbef",
   "metadata": {},
   "source": [
    "### Этап 2. Чтение файлов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eacdb7e",
   "metadata": {},
   "source": [
    "#### Просмотр содержимого папки /content/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c547730",
   "metadata": {},
   "source": [
    "##### Модуль os и метод .walk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ebdcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выводим пути к папкам (dirpath) и наименования файлов (filenames)\n",
    "# и после этого\n",
    "for dirpath, _, filenames in os.walk(\"/content/\"):\n",
    "\n",
    "    # во вложенном цикле проходимся по названиям файлов\n",
    "    for filename in filenames:\n",
    "\n",
    "        # и соединяем путь до папок и входящие в эти папки файлы\n",
    "        # с помощью метода path.join()\n",
    "        print(os.path.join(dirpath, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012fe9ea",
   "metadata": {},
   "source": [
    "##### Команда `!ls`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36116040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на содержимое папки content\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c854f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# заглянем внутрь sample_data\n",
    "!ls /content/sample_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f17726",
   "metadata": {},
   "source": [
    "#### Чтение из переменной uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76369878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на тип значений словаря uploaded\n",
    "type(uploaded[\"test.csv\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac39c91d",
   "metadata": {},
   "source": [
    "Пример работы с объектом bytes      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обратимся к ключу словаря uploaded и применим метод .decode()\n",
    "uploaded_str: str = uploaded[\"test.csv\"].decode()\n",
    "\n",
    "# на выходе получаем обычную строку\n",
    "print(type(uploaded_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e36fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выведем первые 35 значений\n",
    "print(uploaded_str[:35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c66e7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# если разбить строку методом .split() по символам \\r\n",
    "# (возврат к началу строки) и \\n (новая строка)\n",
    "uploaded_list: list[str] = uploaded_str.split(\"\\r\\n\")\n",
    "\n",
    "# на выходе мы получим список\n",
    "type(uploaded_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dec503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# пройдемся по этому списку, не забыв создать индекс\n",
    "# с помощью функции enumerate()\n",
    "for i, line in enumerate(uploaded_list):\n",
    "\n",
    "    # начнем выводить записи\n",
    "    print(line)\n",
    "\n",
    "    # когда дойдем до четвертой строки\n",
    "    if i == 3:\n",
    "\n",
    "        # прервемся\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20ab1ca",
   "metadata": {},
   "source": [
    "#### Использование функции open() и конструкции with open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165b8e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# передадим функции open() адрес файла\n",
    "# параметр 'r' означает, что мы хотим прочитать (read) файл\n",
    "# f1: TextIO = open(\"/content/train.csv\")\n",
    "\n",
    "# метод .read() помещает весь файл в одну строку\n",
    "# выведем первые 142 символа (если параметр не указывать,\n",
    "# выведется все содержимое)\n",
    "# print(f1.read(142))\n",
    "\n",
    "# в конце файл необходимо закрыть\n",
    "# f1.close()\n",
    "\n",
    "# учитывая требования линтеров код был скорретирован\n",
    "# следующим образом:\n",
    "with open(\"file.txt\", encoding=\"utf-8\") as f1:\n",
    "    data = f1.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39256ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# снова откроем файл\n",
    "# f2: TextIO = open(\"/content/train.csv\")\n",
    "with open(\"/content/train.csv\", encoding=\"utf-8\") as f2:\n",
    "\n",
    "    # пройдемся по нашему объекту в цикле for и параллельно создадим индекс\n",
    "    for i, line in enumerate(f2):\n",
    "\n",
    "        # выведем строки без служебных символов по краям\n",
    "        print(line.strip())\n",
    "\n",
    "        # дойдя до четвертой строки, прервемся\n",
    "        if i == 3:\n",
    "            break\n",
    "\n",
    "# не забудем закрыть файл\n",
    "# f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3334d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# скажем Питону: \"открой файл  и назови его f3\"\n",
    "with open(\"/content/test.csv\", encoding=\"utf-8\") as f3:\n",
    "\n",
    "    # \"пройдись по строкам без служебных символов\"\n",
    "    for i, line in enumerate(f3):\n",
    "        print(line.strip())\n",
    "\n",
    "        # и \"прервись на четвертой строке\"\n",
    "        if i == 3:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868de4dc",
   "metadata": {},
   "source": [
    "#### Чтение через библиотеку Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7acf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим функцию read_csv() и посмотрим\n",
    "# на первые три записи файла train.csv\n",
    "train: pd.DataFrame = pd.read_csv(\"/content/train.csv\")\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a1bf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем то же самое с файлом test.csv\n",
    "test: pd.DataFrame = pd.read_csv(\"/content/test.csv\")\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c594c0",
   "metadata": {},
   "source": [
    "### Этап 3. Построение модели и прогноз"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff817b1",
   "metadata": {},
   "source": [
    "#### **Шаг 1**. Обработка и анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a4dc64",
   "metadata": {},
   "source": [
    "Исследовательский анализ данных (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add03044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на данные в целом\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13563d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим насколько значим класс билета для выживания пассажира\n",
    "# с помощью x и hue мы можем уместить две категориальные переменные\n",
    "# на одном графике\n",
    "sns.countplot(x=\"Pclass\", hue=\"Survived\", data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7979b36",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5100b2",
   "metadata": {},
   "source": [
    "Пропущенные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f9c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выявим пропущенные значения с помощью .isnull()\n",
    "# и посчитаем их количество через sum()\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5630fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# переменная Cabin (номер каюты), скорее всего, не является самой важной\n",
    "# избавимся от нее с помощью метода .drop()\n",
    "# (параметр axis = 1 отвечает за столбцы, inplace = True сохраняет изменения)\n",
    "train.drop(columns=\"Cabin\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee341bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# а вот Age (возраст) скорее важен, заменим пустые значения\n",
    "# средним арифметическим\n",
    "train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49daf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# у нас остаются две пустые строки в Embarked, удалим их\n",
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0691b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на результат\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf88c2f",
   "metadata": {},
   "source": [
    "Категориальные переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caf69aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим one-hot encoding к переменной Sex (пол)\n",
    "# с помощью функции pd.get_dummies()\n",
    "pd.get_dummies(train[\"Sex\"]).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621cfa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# снова скачаем столбец Sex из датасета train в формате датафрейма\n",
    "previous: pd.DataFrame = pd.read_csv(\"/content/train.csv\")[[\"Sex\"]]\n",
    "previous.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c188a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# закодируем переменную через 0 и 1\n",
    "pd.get_dummies(previous[\"Sex\"], dtype=int).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3ae6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим первый столбец, он избыточен\n",
    "sex: pd.DataFrame = pd.get_dummies(train[\"Sex\"], drop_first=True)\n",
    "sex.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb2a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем то же самое для переменных Pclass и Embarked\n",
    "embarked: pd.DataFrame = pd.get_dummies(train[\"Embarked'\"], drop_first=True)\n",
    "pclass: pd.DataFrame = pd.get_dummies(train[\"Pclass\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db65d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# присоединим закодированные через one-hot encoding переменные\n",
    "# к исходному датафрейму через функцию .concat()\n",
    "train = pd.concat([train, pclass, sex, embarked], axis=1)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6067e64d",
   "metadata": {},
   "source": [
    "Отбор признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8478cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим те столбцы, которые нам теперь не нужны\n",
    "id_columns = [\"PassengerId\", \"Name\", \"Ticket\"]\n",
    "categorical_columns = [\"Pclass\", \"Sex\", \"Embarked\"]\n",
    "columns_to_drop = id_columns + categorical_columns\n",
    "train.drop(columns_to_drop, axis=1, inplace=True)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb957f8d",
   "metadata": {},
   "source": [
    "Нормализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac9d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим объект этого класса\n",
    "scaler: StandardScaler = StandardScaler()\n",
    "\n",
    "# выберем те столбцы, которые мы хотим масштабировать\n",
    "cols_to_scale: list[str] = [\"Age\", \"Fare\"]\n",
    "\n",
    "# рассчитаем среднее арифметическое и СКО для масштабирования данных\n",
    "scaler.fit(train[cols_to_scale])\n",
    "\n",
    "# применим их\n",
    "train[cols_to_scale] = scaler.transform(train[cols_to_scale])\n",
    "\n",
    "# посмотрим на результат\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b87e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# некоторые названия столбцов теперь представляют собой числа,\n",
    "# так быть не должно\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ca9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
